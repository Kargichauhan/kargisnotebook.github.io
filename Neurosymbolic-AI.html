<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ðŸ§  Neurosymbolic AI: When Logic Meets Learning</title>
  <link rel="stylesheet" href="../style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@400;600&display=swap" rel="stylesheet" />
  <style>
    body {
      max-width: 760px;
      margin: auto;
      padding: 2.5rem 1rem;
      font-family: 'Outfit', sans-serif;
      background-color: #1c1c1c;
      color: #f5f5f5;
      line-height: 1.7;
      font-size: 1.05rem;
    }

    h1 {
      font-size: 2.2rem;
      margin-bottom: 0.5rem;
    }

    .meta {
      font-size: 0.9rem;
      color: #bbb;
      margin-bottom: 2rem;
    }

    details.toc {
      background: #2a2a2a;
      padding: 1rem;
      border-radius: 10px;
      margin-bottom: 2rem;
    }

    details.toc a {
      color: #90ee90;
      text-decoration: none;
      transition: all 0.2s ease;
    }

    details.toc a:hover {
      color: #b1f1b5;
      text-decoration: underline;
    }

    h2 {
      color: #b4f6b4;
      margin-top: 2.5rem;
    }

    ul {
      padding-left: 1.4rem;
    }

    code {
      background: #2e2e2e;
      padding: 0.25rem 0.4rem;
      border-radius: 5px;
      font-size: 0.95rem;
      color: #b6f5c4;
    }

    pre {
      background: #2e2e2e;
      padding: 1rem;
      border-radius: 8px;
      overflow-x: auto;
      color: #c7f5d2;
      font-family: monospace;
      font-size: 0.9rem;
    }

    .cite-box {
      background: #2b2b2b;
      padding: 1rem;
      border-radius: 8px;
      margin-top: 1rem;
      white-space: pre-wrap;
      font-family: monospace;
      font-size: 0.9rem;
      color: #d0f7cf;
    }

    .refs li {
      margin-bottom: 0.6rem;
    }

    a {
      color: #98f7aa;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
</head>

<body>
  <h1> Neurosymbolic AI: When Logic Meets Learning</h1>
  <p class="meta">Date: May 1, 2025 â€¢ Estimated Reading Time: 10 min â€¢ Author: Kargi Chauhan</p>

  <details class="toc">
    <summary>Table of Contents</summary>
    <ul>
      <li><a href="#what-is">What is Neurosymbolic AI?</a></li>
      <li><a href="#why-it-matters">Why It Matters</a></li>
      <li><a href="#ltn">Example: Logic Tensor Networks</a></li>
      <li><a href="#future">Challenges and Future</a></li>
      <li><a href="#citation">Citation</a></li>
      <li><a href="#references">References</a></li>
    </ul>
  </details>

  <h2 id="what-is">What is Neurosymbolic AI?</h2>
  <p>
    Neurosymbolic AI is a hybrid approach that combines symbolic reasoning (like logic rules and ontologies) with neural network-based learning (like transformers or CNNs). 
    It aims to bring together the strengths of <strong>structure</strong> and <strong>data-driven generalization</strong>.
  </p>

  <h2 id="why-it-matters">Why It Matters</h2>
  <p>
    Purely neural models lack <strong>explainability</strong>, and symbolic systems lack <strong>flexibility</strong>. Neurosymbolic systems can reason over facts and learn from data â€” bridging the gap between <code>deduction</code> and <code>pattern recognition</code>.
  </p>

  <h2 id="ltn">Example: Logic Tensor Networks</h2>
  <p>
    LTNs integrate first-order logic into deep learning by relaxing logical operators using continuous semantics. For instance, you can encode:
  </p>
  <pre><code>âˆ€x: Human(x) â†’ Mortal(x)</code></pre>
  <p>
    and train your model to learn embeddings that <strong>satisfy these constraints</strong> while fitting the data.
  </p>

  <h2 id="future">Challenges and Future</h2>
  <p>
    While promising, neurosymbolic AI is still under research. Open questions include:
  </p>
  <ul>
    <li>How to scale logic reasoning to real-world datasets?</li>
    <li>How to balance interpretability and model capacity?</li>
    <li>Can LLMs be guided by symbolic priors?</li>
  </ul>

  <h2 id="citation">Citation</h2>
  <p>Cite this blog post as:</p>
  <p><strong>Kargi Chauhan.</strong> (May 2025). <em>Neurosymbolic AI: When Logic Meets Learning</em>. KC's Log.  
    https://kargichauhan.github.io/kargisnotebook.github.io/posts/neurosymbolic-ai.html</p>

  <p><strong>Or in BibTeX:</strong></p>
  <div class="cite-box">
@article{kargi2025neurosymbolic,
  title   = "Neurosymbolic AI: When Logic Meets Learning",
  author  = "Kargi Chauhan",
  journal = "kargisnotebook.github.io",
  year    = "2025",
  month   = "May",
  url     = "https://kargichauhan.github.io/kargisnotebook.github.io/posts/neurosymbolic-ai.html"
}
  </div>

  <h2 id="references">References</h2>
  <ol class="refs">
    <li>Garcez, A. d. et al. "Neurosymbolic AI: The Third Wave." *Communications of the ACM* (2020)</li>
    <li>Serafini, L., & Garcez, A. "Logic Tensor Networks: Deep Learning and Logical Reasoning." *arXiv:1606.04422*</li>
    <li>Besold et al. "Neural-Symbolic Learning and Reasoning." *Springer* (2017)</li>
    <li>Marcus, G. "The Next Decade in AI: Why Common Sense Matters." *arXiv:2002.06177*</li>
  </ol>
</body>
</html>
