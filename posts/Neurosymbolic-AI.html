<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Neurosymbolic AI: When Logic Meets Learning</title>
  <link rel="stylesheet" href="../style.css" />
  <link rel="icon" href="../favicon.ico" type="image/x-icon" />
  <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@400;600&display=swap" rel="stylesheet"/>
  <style>
    body {
      max-width: 760px;
      margin: auto;
      padding: 2.5rem 1rem;
      font-family: 'Outfit', sans-serif;
      background-color: var(--bg);
      color: var(--text);
      transition: background 0.3s ease, color 0.3s ease;
      font-size: 1.05rem;
      line-height: 1.7;
    }
    h1 { font-size: 2.2rem; margin-bottom: 0.5rem; }
    .meta { font-size: 0.9rem; color: var(--meta); margin-bottom: 2rem; }

    details.toc {
      background: var(--card);
      padding: 1rem;
      border-radius: 10px;
      margin-bottom: 2rem;
    }
    details.toc a {
      color: #74e474;
      text-decoration: none;
    }
    details.toc a:hover {
      text-decoration: underline;
    }

    h2 { color: #7bed9f; margin-top: 2.5rem; }
    pre, code {
      background: #2e2e2e;
      padding: 0.25rem 0.4rem;
      border-radius: 5px;
      color: #b8f5c8;
    }
    pre {
      padding: 1rem;
      overflow-x: auto;
    }
    .citation-container { position: relative; margin-top: 1rem; }
    .cite-box {
      background: #2b2b2b;
      padding: 1rem;
      border-radius: 8px;
      white-space: pre-wrap;
      font-family: monospace;
      font-size: 0.9rem;
      color: #d0f7cf;
    }
    #copy-btn {
      position: absolute;
      top: 10px;
      right: 10px;
      background-color: #4caf50;
      color: white;
      border: none;
      padding: 0.4rem 0.8rem;
      border-radius: 6px;
      cursor: pointer;
      font-size: 0.8rem;
    }
    #copy-btn:hover { background-color: #45a049; }
    .refs li { margin-bottom: 0.6rem; }
    a { color: #8ff7a4; }
    a:hover { text-decoration: underline; }

    #theme-toggle {
      position: fixed;
      top: 1rem;
      right: 1rem;
      width: 2.5rem;
      height: 2.5rem;
      border: none;
      border-radius: 50%;
      background: var(--card);
      font-size: 1.2rem;
      cursor: pointer;
      box-shadow: 0 2px 6px rgba(0,0,0,0.2);
    }

    :root[data-theme="light"] {
      --bg: #f8fff5;
      --text: #1a1a1a;
      --card: #ffffff;
      --meta: #555;
    }
    :root[data-theme="dark"] {
      --bg: #1c1c1c;
      --text: #f5f5f5;
      --card: #2a2a2a;
      --meta: #bbb;
    }
  </style>
</head>
<body>
  <button id="theme-toggle">üåô</button>

  <h1>Neurosymbolic AI: When Logic Meets Learning</h1>
  <p class="meta">Date: May 1, 2025 ‚Ä¢ Estimated Reading Time: 15 min ‚Ä¢ Author: Kargi Chauhan</p>

  <details class="toc">
    <summary>Table of Contents</summary>
    <ul>
      <li><a href="#what-is">What Is Neurosymbolic AI?</a></li>
      <li><a href="#why-it-matters">Why It Matters</a></li>
      <li><a href="#example">A Closer Look at Logic Tensor Networks</a></li>
      <li><a href="#challenges-future">Challenges and What‚Äôs Next</a></li>
      <li><a href="#citation">Citation</a></li>
      <li><a href="#references">References</a></li>
    </ul>
  </details>

  <h2 id="what-is">What Is Neurosymbolic AI?</h2>
  <p>
    Neurosymbolic AI brings together two very different worlds. On one side, we have neural networks that learn from raw data, finding patterns in images, text, or audio without any explicit rules. On the other side, we have symbolic systems built on logic and structured knowledge, which can explain their decisions but struggle to handle noisy inputs. Neurosymbolic AI combines these strengths, letting a single system learn from examples while still respecting logical constraints and human-understandable rules.
  </p>

  <h2 id="why-it-matters">Why It Matters</h2>
  <p>
    Purely neural approaches often feel like a black box: they can recognize faces or translate languages, but it‚Äôs hard to say how or why. Purely symbolic approaches can explain every step, yet they break down when the data is messy or incomplete. By fusing both, we get systems that can learn flexibility from data and still give us a clear, rule-based explanation when it matters‚Äîfor example, in medical diagnosis, where a doctor needs to trust the reasoning behind an AI‚Äôs suggestion.
  </p>
  <p>
    Neurosymbolic models also excel at compositional tasks. Imagine asking a robot not just to ‚Äúpick up the red block,‚Äù but to understand a sequence like ‚Äúplace the red block on the blue one, then move the stack to the corner.‚Äù The symbolic layer handles the plan, while the neural layer handles perception and motor control.
  </p>

  <h2 id="example">A Closer Look at Logic Tensor Networks</h2>
  <p>
    One of the most influential neurosymbolic frameworks is the Logic Tensor Network (LTN). In an LTN, logical statements are translated into differentiable loss functions. Take the rule ‚Äúevery human is mortal.‚Äù In classical logic, that reads ‚àÄx: Human(x) ‚Üí Mortal(x). In an LTN, we measure how much a learned embedding of ‚Äúhuman‚Äù and ‚Äúmortal‚Äù violate this rule, and we add that to our training loss.
  </p>
  <pre><code>‚àÄx: Human(x) ‚Üí Mortal(x)</code></pre>
  <p>
    During training, the network adjusts so that the numeric representations of ‚ÄúHuman‚Äù and ‚ÄúMortal‚Äù satisfy this implication as closely as possible. This gives us models that not only fit the data but also respect the logical structure we care about.
  </p>

  <h2 id="challenges-future">Challenges and What‚Äôs Next</h2>
  <p>
    Neurosymbolic AI is still a young field, and there are open questions everywhere. Scaling logic engines to handle real-world, large-scale data remains difficult, because the number of possible logical combinations can explode. We also need better ways to translate between discrete symbols and continuous vectors without losing meaning.
  </p>
  <p>
    Looking ahead, researchers are exploring end-to-end differentiable theorem provers, new methods for automatically discovering symbolic rules from data, and hardware accelerators designed for mixed symbolic‚Äìneural workloads. The dream is a system that learns new rules on the fly, explains its reasoning to humans, and adapts to entirely novel situations.
  </p>

  <h2 id="citation">Citation</h2>
  <div class="citation-container">
    <pre id="bibtex" class="cite-box">@article{kargi2025neurosymbolic,
  title   = "Neurosymbolic AI: When Logic Meets Learning",
  author  = "Kargi Chauhan",
  journal = "kargisnotebook.github.io",
  year    = "2025",
  month   = "May",
  url     = "https://kargichauhan.github.io/posts/neurosymbolic-ai.html"
}</pre>
    <button id="copy-btn">üìã Copy</button>
  </div>

  <h2 id="references">References</h2>
  <ol class="refs">
    <li>
      Besold, T. R., d‚ÄôAvila Garcez, A., Bader, S., Bowman, H., Domingos, P., Hitzler, P., ‚Ä¶ &amp; Zaverucha, G. 
      Neural‚ÄêSymbolic Learning and Reasoning: A Survey and Interpretation. <em>ArXiv</em>, 2017.
    </li>
    <li>
      Serafini, L. &amp; d‚ÄôAvila Garcez, A. Logic Tensor Networks: Deep Learning and Logical Reasoning. 
      <em>ArXiv:1606.04422</em>, 2016.
    </li>
    <li>
      Manhaeve, R., Dumancic, S., Kimmig, A., Demeester, T., &amp; De Raedt, L. DeepProbLog: Neural Probabilistic Logic Programming. 
      <em>NeurIPS</em>, 2018.
    </li>
    <li>
      Mao, J., Gan, C., Kohli, P., Tenenbaum, J. B., &amp; Wu, J. Neuro‚ÄêSymbolic Concept Learner: Interpreting Scenes, Words, and Sentences from Natural Supervision. 
      <em>ICLR</em>, 2019.
    </li>
    <li>
      Marcus, G. The Next Decade in AI: Why Common Sense Matters. <em>ArXiv:2002.06177</em>, 2020.
    </li>
  </ol>

  <script>
    // Initialize theme
    const htmlEl = document.documentElement;
    const savedTheme = localStorage.getItem('theme') || 'light';
    htmlEl.dataset.theme = savedTheme;

    // Toggle button
    const toggleBtn = document.getElementById('theme-toggle');
    toggleBtn.textContent = savedTheme === 'light' ? 'üåô' : '‚òÄÔ∏è';
    toggleBtn.addEventListener('click', () => {
      const next = htmlEl.dataset.theme === 'light' ? 'dark' : 'light';
      htmlEl.dataset.theme = next;
      localStorage.setItem('theme', next);
      toggleBtn.textContent = next === 'light' ? 'üåô' : '‚òÄÔ∏è';
    });

    // Copy BibTeX
    document.getElementById('copy-btn').addEventListener('click', () => {
      navigator.clipboard.writeText(document.getElementById('bibtex').textContent).then(() => {
        const btn = document.getElementById('copy-btn');
        btn.textContent = '‚úÖ Copied!';
        setTimeout(() => btn.textContent = 'üìã Copy', 2000);
      });
    });
  </script>
</body>
</html>
